{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN+27zClBK5dOju1JG7znua",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Javsk891/PySpark-Projects-Repository/blob/main/PySpark_%2B_Kaggle.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Usando PySpark para importar data desde Kaggle\n",
        "\n",
        "En este proyecto, exploraremos cómo importar y manejar grandes volúmenes de datos utilizando `PySpark` en Google Colab. `PySpark`, la interfaz de Python para `Apache Spark`, es una herramienta potente para procesar y analizar grandes conjuntos de datos de manera distribuida y eficiente.\n",
        "\n",
        "Para ilustrar este proceso, utilizaremos el dataset de detección de deforestación disponible en Kaggle. Este dataset contiene información valiosa sobre la deforestación a nivel global y puede ser extremadamente grande, lo que lo convierte en un excelente caso de estudio para aprender cómo manejar datos voluminosos.\n",
        "\n",
        "\n",
        "Dataset: Deforestation Detection Dataset\n",
        "\n",
        "En los siguientes pasos, mostraremos cómo:\n",
        "\n",
        "\n",
        "1. Configurar el entorno de Google Colab para usar `PySpark`.\n",
        "2. Descargar el dataset directamente desde Kaggle.\n",
        "3. Leer el dataset en `PySpark` y realizar algunas operaciones básicas para comprobar su integridad.\n",
        "\n",
        "\n",
        "El objetivo es demostrar la eficacia de `PySpark` para el manejo de grandes conjuntos de datos y cómo integrarlo con Google Colab para facilitar el análisis de datos a gran escala."
      ],
      "metadata": {
        "id": "0teVvS6mE-lS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ce-K1hDmE9eb",
        "outputId": "693f1d66-43fe-4697-fa60-5cd18f751bff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.2)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "# Instalamos PySpark\n",
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Iniciando una sesión de PySpark para activar todas sus funcionalidades\n",
        "\n",
        "Una vez que hemos instalado `PySpark` en nuestro entorno de Google Colab, el siguiente paso crucial es crear una sesión de `Spark`. La sesión de `Spark` es el punto de entrada principal para cualquier funcionalidad de `Spark` y es esencial para trabajar con datos en `PySpark`. A continuación, desglosamos las líneas de código necesarias para crear esta sesión y su propósito en el contexto de nuestro proyecto:"
      ],
      "metadata": {
        "id": "VWPxpmOAF0SW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ahora que instalamos PySpark, debemos abrir una sesión (SparkSession) que es el punto de entrada para cualquier fincionalidad de Spark\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"SparkML\").getOrCreate()"
      ],
      "metadata": {
        "id": "_GScrvrdFQ7y"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importamos el dataset con el que queremos trabajar desde kaggle"
      ],
      "metadata": {
        "id": "-6YpOEbXKYaj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esta línea utiliza pip para instalar la biblioteca kaggle en tu entorno de Google Colab. La biblioteca kaggle permite interactuar con la API de Kaggle, facilitando la descarga de datasets y la participación en competiciones directamente desde el código. Este paso es necesario para trabajar con datasets alojados en Kaggle.\n",
        "\n",
        "from google.colab import files: Importa el módulo files desde la biblioteca de Google Colab. Este módulo proporciona herramientas para manejar archivos en el entorno de Colab.\n",
        "files.upload(): Abre un cuadro de diálogo que permite seleccionar y subir archivos desde tu sistema local al entorno de Google Colab. Esto es útil para cargar archivos necesarios para el proyecto, como archivos de configuración, credenciales o datasets."
      ],
      "metadata": {
        "id": "9P-3pprRYdkL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle\n",
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "spgFNZJOKiMK",
        "outputId": "d4419a6c-0810-4404-846d-717f821dbcf4"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.17)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.7.4)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.5)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.8)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-fc52fcd1-abdf-49ad-a52d-06462365ef16\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-fc52fcd1-abdf-49ad-a52d-06462365ef16\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle (2).json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle (2).json': b'{\"username\":\"javiergonzalez1\",\"key\":\"a6861c714d09e77dfb86e2e54e202cb5\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "mkdir -p ~/.kaggle: Este comando crea un directorio llamado .kaggle en el directorio home del usuario (~). La opción -p asegura que se crea el directorio sin errores si ya existe. Este directorio es donde se almacenará el archivo de credenciales de Kaggle (kaggle.json).\n",
        "\n",
        "cp kaggle.json ~/.kaggle/: Este comando copia el archivo kaggle.json, que contiene las credenciales de autenticación de la API de Kaggle, al directorio .kaggle que acabamos de crear. Este archivo es necesario para autenticar las solicitudes a la API de Kaggle.\n",
        "\n",
        "chmod 600 ~/.kaggle/kaggle.json: Este comando cambia los permisos del archivo kaggle.json para que sólo el propietario (el usuario actual) tenga permiso de lectura y escritura. Esto es una medida de seguridad para proteger el archivo de credenciales, asegurando que sólo el usuario que lo subió pueda acceder a él."
      ],
      "metadata": {
        "id": "utUDfD4uY2Hh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos la ruta de acceso al dataset\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "MZ8hEKs-K3c6"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "!kaggle: El símbolo ! se usa en Google Colab para ejecutar comandos de la línea de comandos del sistema operativo desde una celda de código. En este caso, estamos ejecutando un comando relacionado con la herramienta de línea de comandos de Kaggle.\n",
        "\n",
        "datasets download: Este es un subcomando de la herramienta de línea de comandos de Kaggle que indica que queremos descargar un dataset.\n",
        "\n",
        "-d akhilchibber/deforestation-detection-dataset: La opción -d se utiliza para especificar el identificador del dataset en Kaggle. En este caso, akhilchibber/deforestation-detection-dataset es el identificador del dataset que queremos descargar. Este identificador se compone del nombre de usuario de Kaggle y el nombre del dataset."
      ],
      "metadata": {
        "id": "gu4BywfpZK1R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d akhilchibber/deforestation-detection-dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oF55LWnmPX6M",
        "outputId": "8aa2b5c5-4d85-480f-a59a-566190bc10e9"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/akhilchibber/deforestation-detection-dataset\n",
            "License(s): MIT\n",
            "deforestation-detection-dataset.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "import zipfile: Importa el módulo zipfile, que proporciona herramientas para trabajar con archivos ZIP en Python.\n",
        "\n",
        "from zipfile import ZipFile: Importa la clase ZipFile del módulo zipfile, que permite abrir y manipular archivos ZIP.\n",
        "\n",
        "path = \"/content/deforestation-detection-dataset.zip\": Define la ruta al archivo ZIP descargado. En Google Colab, los archivos se descargan en el directorio /content/, por lo que path apunta a la ubicación del archivo ZIP en ese directorio.\n",
        "\n",
        "zip_ref = zipfile.ZipFile(path): Crea una instancia de ZipFile para el archivo ZIP especificado en path. Esta instancia permite acceder y manipular el contenido del archivo ZIP.\n",
        "\n",
        "zip_ref.extractall(): Extrae todos los archivos contenidos en el archivo ZIP al directorio actual (en este caso, al directorio /content/). Esto hace que los archivos estén disponibles para su uso en el entorno de Google Colab.\n",
        "\n",
        "zip_ref.close(): Cierra el archivo ZIP una vez que la extracción ha terminado. Es una buena práctica cerrar archivos abiertos para liberar recursos del sistema."
      ],
      "metadata": {
        "id": "DZFbU8HEZSOQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ahora vamos a descomprimir la data\n",
        "\n",
        "import zipfile\n",
        "from zipfile import ZipFile\n",
        "path = \"/content/deforestation-detection-dataset.zip\"\n",
        "zip_ref = zipfile.ZipFile(path)\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "jvVZ11jgMQP5"
      },
      "execution_count": 30,
      "outputs": []
    }
  ]
}